#
# 开发环境配置文件
#
#########################################

# 全局配置
logfile                 = 'config/log.json'     # 日志存放位置，若配置后无对应的path, 则也会输出至os.Stdout default: os.Stdout
http_server_port        = 9308                  # 对接maybach的http服务端口

tip                     = '0.0.0.0'             # thrift服务绑定IP
tport                   = 10002                  # thrift服务监听端口
ttimeout                = '0ms'                 # 客户端超时时间

[redisCfg]
    redis_svr               = ["10.1.11.204:19000",
                               "10.1.11.205:19000",
                                ]
    redis_conn_timeout      = 1000                      # redis连接超时 毫秒
    redis_read_timeout      = 500                       # redis读超时 毫秒
    redis_write_timeout     = 500                       # redis写超时 毫秒
    redis_max_idle          = 200                       # 最大空闲连接
    redis_max_active        = 2000                      # 最大活动连接
    redis_expire_second     = 600                       # redis数据过期时间 秒 线上配置10分钟 60

[javaThriftGW]
    host = "10.1.11.201"
    port = "18900"
    key = "fhA4hUoBcReZ8bJddPKkqCE42sn0PzoX"
    tokenexpire = 500

[downstreams]
     [downstreams.mars]
        servers             = [                     # 下游服务器IP端口列表
        ]
        healthythreshold    = 10                    # 健康阈值
        maxcooldowntime     = 30                    # 冷却时长
        minhealthyratio     = 1.0                   # 最小健康比
        connsize            = 1000                  # 每个地址对应的连接池大小
        timeout             = '30000ms'              # 超时时间
        cycle               = '1000ms'              # 健康检查的时间周期
        retrytimes          = 0                     # 创建连接失败重试次数
        maxconnfalsecnt     = 1                     # 单个连接允许出错次数，超过这个次数就close这个连接
        checkaliveconnsessioncycle  = '10000ms'          #多久檢查一次[kill 一段時間沒被使用的連線]
        connsessionalivetime        = '10000ms'         #多久沒被使用後, 就close這個Session

[apollo]
    apinamelistkey = "API_NAME_LIST"
    appid = "magneto"
    cluster = "default"
    namespaceName = "application"
    configserver = "apollo-fat.kb.com"

[apollodefault]
    apinamelist = ["mars"]
    [apollodefault.apiinfo]
        [apollodefault.apiinfo.mars]
            servers             = [
                "10.1.11.210:16601"
            ]
            protocol = "thrift"

[kafkaProducerCfg]
    brokerlist      = "10.1.11.204:9092,10.1.11.205:9092,10.1.11.206:9092"
    batchnum        = 3
    partitionnum    = 10
    producenum      = 1
    dialtimeout     = 1000
    writetimeout    = 5000
    readtimeout     = 5000
    returnerror     = true
    returnsuccess   = true
    flushfrequency  = 100
    channelbuffersize = 100000

[kafkaConsumerCfg]
    [kafkaConsumerCfg.CHATROOM]
        topic                   = 'CHATROOM' #订阅的topic, 必需
        group                   = ''                    #位于的gourp, default:'default'
        processTimeout          = 25000                 #任务可以处理的时间 default: '60s'
        commitInterval          = 5000                  #提交offset数据的间隔 default: '10s'
        retryTimes              = 3                     #任务失败后的重试次数 default: 5
        metaMaxRetry            = 3                     #获取meta信息失败后的重试次数 default:3
        channelSize             = 20                    #本地允许缓存的消息条数 default: 256
        httpTimeout             = 20000                 #处理任务时http调用的超时时间 default: 20s
        zookeeperTimeout        = 1000                  #连接zookeeper的超时时间 default: '1s'
        metaRefreshFrequency    = 60000                 #meta信息的刷新频率 default: '20min'
        zookeeperChroot         = ''                    #zookeeper chroot default: ''
        retryInterval           = 500                   #messgae handle 失败后
        zookeeperAddresses      = [
                                      "10.1.11.204:2181",
                                      "10.1.11.205:2181",
                                      "10.1.11.206:2181",
                                    ]